"""
Agentic Context Loader ‚Äî –º–æ–¥–µ–ª—å —Å–∞–º–∞ –≤—ã–±–∏—Ä–∞–µ—Ç –Ω—É–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã —á–µ—Ä–µ–∑ MCP tools

–õ–æ–≥–∏–∫–∞:
1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ tools –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞ (tools/list)
2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI tools
3. –î–∞—ë–º –º–æ–¥–µ–ª–∏ –∑–∞–¥–∞—á—É + tools
4. –ú–æ–¥–µ–ª—å –≤—ã–∑—ã–≤–∞–µ—Ç tools ‚Üí –ø—Ä–æ–∫—Å–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ tools/call
5. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤
"""

import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any

from ..clients.openrouter import OpenRouterClient
from ..clients.mcp import MCPClient
from ..schemas.results import ContextLoadResult, ChatMessage
from ..utils.file_ops import load_yaml


# Finish tool ‚Äî –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ MCP tools
FINISH_TOOL = {
    "type": "function",
    "function": {
        "name": "finish_research",
        "description": "–ó–∞–≤–µ—Ä—à–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö. –í—ã–∑–æ–≤–∏ –∫–æ–≥–¥–∞ —Å–æ–±—Ä–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞.",
        "parameters": {
            "type": "object",
            "properties": {
                "summary": {
                    "type": "string",
                    "description": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ: –∫–∞–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –±—É–¥–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ –ø–æ—á–µ–º—É"
                }
            },
            "required": ["summary"]
        }
    }
}


class AgenticContextLoader:
    """
    Agentic –∑–∞–≥—Ä—É–∑—á–∏–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –º–æ–¥–µ–ª—å —Å–∞–º–∞ –≤—ã–±–∏—Ä–∞–µ—Ç —á—Ç–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å —á–µ—Ä–µ–∑ MCP tools
    
    –ü–æ–ª—É—á–∞–µ—Ç tools –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞ (vladimir-kharin/1c_mcp)
    –ü—Ä–æ–º–ø—Ç—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    """
    
    def __init__(
        self,
        mcp_client: MCPClient,
        llm_client: OpenRouterClient,
        analysis_model: str = "google/gemini-2.0-flash-001",
        config_dir: str = "config"
    ):
        """
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            mcp_client: –ö–ª–∏–µ–Ω—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å connected)
            llm_client: –ö–ª–∏–µ–Ω—Ç OpenRouter
            analysis_model: –ú–æ–¥–µ–ª—å –¥–ª—è –∞–≥–µ–Ω—Ç–∞ (–¥–æ–ª–∂–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å tools)
            config_dir: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∫–æ–Ω—Ñ–∏–≥–∞–º–∏
        """
        self.mcp = mcp_client
        self.llm = llm_client
        self.agent_model = analysis_model
        self.config_dir = Path(config_dir)
        self._structure_cache: Dict[Tuple[str, str], str] = {}
        self._mcp_tools: Optional[List[Dict]] = None
        self._agent_prompts: Optional[Dict[str, str]] = None
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self.total_tokens = 0
        self.total_cost = 0.0
        self.tool_calls_count = 0
    
    def _load_agent_prompts(self, category: str = "B") -> Dict[str, str]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –∞–≥–µ–Ω—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        if self._agent_prompts is not None:
            return self._agent_prompts
        
        config_path = self.config_dir / f"tasks_category_{category}.yaml"
        config = load_yaml(config_path)
        
        agent_prompts = config.get("agent_prompts", {})
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        self._agent_prompts = {
            "system": agent_prompts.get("system", "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ 1–°. –ò–∑—É—á–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–∑–æ–≤–∏ finish_research."),
            "user_template": agent_prompts.get("user_template", "–ó–∞–¥–∞—á–∞:\n{task_prompt}\n\n–ò–∑—É—á–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.")
        }
        
        return self._agent_prompts
    
    async def _get_tools(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å tools –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
        """
        if self._mcp_tools is not None:
            return self._mcp_tools
        
        mcp_tools_raw = await self.mcp.list_tools()
        
        if not mcp_tools_raw:
            print("[–ê–≥–µ–Ω—Ç] –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ –≤–µ—Ä–Ω—É–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã")
            self._mcp_tools = [FINISH_TOOL]
            return self._mcp_tools
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MCP tools –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
        openai_tools = []
        for tool in mcp_tools_raw:
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.get("name", ""),
                    "description": tool.get("description", ""),
                    "parameters": tool.get("inputSchema", {"type": "object", "properties": {}})
                }
            }
            openai_tools.append(openai_tool)
            print(f"   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool.get('name')}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º finish_research tool
        openai_tools.append(FINISH_TOOL)
        
        self._mcp_tools = openai_tools
        return self._mcp_tools
    
    async def _execute_tool(self, name: str, arguments: Dict[str, Any]) -> str:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å tool call —á–µ—Ä–µ–∑ MCP —Å–µ—Ä–≤–µ—Ä"""
        self.tool_calls_count += 1
        
        # finish_research –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
        if name == "finish_research":
            summary = arguments.get("summary", "")
            print(f"   –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {summary[:100]}...")
            return "DONE"
        
        # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ tools ‚Äî —á–µ—Ä–µ–∑ MCP
        print(f"  üîß {name}({json.dumps(arguments, ensure_ascii=False)[:80]}...)")
        
        result = await self.mcp.call_tool(name, arguments)
        
        if result:
            # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            result = self._compact_structure(result)
            return result
        
        return f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {name} –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"
    
    def _compact_structure(self, structure: str, max_lines: int = 80) -> str:
        """–°–æ–∫—Ä–∞—Ç–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤"""
        lines = structure.split('\n')
        filtered = [l for l in lines if l.strip() and not l.strip().endswith('- ""')]
        
        if len(filtered) > max_lines:
            filtered = filtered[:max_lines]
            filtered.append("... (—Å–æ–∫—Ä–∞—â–µ–Ω–æ)")
        
        return '\n'.join(filtered)
    
    async def load_context(self, task_prompt: str, max_iterations: int = 10) -> ContextLoadResult:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Å–±–æ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            task_prompt: –¢–µ–∫—Å—Ç –∑–∞–¥–∞–Ω–∏—è
            max_iterations: –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π (–∑–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è)
            
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            ContextLoadResult —Å —Å–æ–±—Ä–∞–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        print("[–ê–≥–µ–Ω—Ç] –ù–∞—á–∏–Ω–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        
        # –ü–æ–ª—É—á–∞–µ–º tools –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞
        tools = await self._get_tools()
        print(f"[–ê–≥–µ–Ω—Ç] –ü–æ–ª—É—á–µ–Ω–æ {len(tools)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        prompts = self._load_agent_prompts()
        
        messages = [
            ChatMessage(role="system", content=prompts["system"]),
            ChatMessage(role="user", content=prompts["user_template"].format(task_prompt=task_prompt))
        ]
        
        loaded_objects: List[Dict[str, str]] = []
        collected_context: List[str] = []
        
        try:
            for iteration in range(max_iterations):
                print(f"[–ê–≥–µ–Ω—Ç] –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration + 1}/{max_iterations}")
                
                # –í—ã–∑—ã–≤–∞–µ–º LLM —Å tools –æ—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞
                result = self.llm.chat_completion(
                    model=self.agent_model,
                    messages=messages,
                    temperature=0,
                    max_tokens=1024,
                    tools=tools
                )
                
                self.total_tokens += result.tokens_total
                self.total_cost += result.tokens_total * 0.000001
                
                if not result.success:
                    print(f"[–ê–≥–µ–Ω—Ç] –û—à–∏–±–∫–∞ LLM: {result.error}")
                    break
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ tool calls
                if not result.tool_calls:
                    print("[–ê–≥–µ–Ω—Ç] –ù–µ—Ç –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –∑–∞–≤–µ—Ä—à–∞—é...")
                    break
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º tool calls
                for tool_call in result.tool_calls:
                    tool_name = tool_call.get("function", {}).get("name")
                    tool_args_str = tool_call.get("function", {}).get("arguments", "{}")
                    tool_id = tool_call.get("id", "")
                    
                    try:
                        tool_args = json.loads(tool_args_str)
                    except json.JSONDecodeError:
                        tool_args = {}
                    
                    # –í—ã–ø–æ–ª–Ω—è–µ–º tool
                    tool_result = await self._execute_tool(tool_name, tool_args)
                    
                    # finish_research ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º
                    if tool_name == "finish_research":
                        print(f"[–ê–≥–µ–Ω—Ç] –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {iteration + 1} –∏—Ç–µ—Ä–∞—Ü–∏–π")
                        return ContextLoadResult(
                            success=True,
                            context_text="\n\n---\n\n".join(collected_context),
                            objects_loaded=loaded_objects,
                            analysis_tokens=self.total_tokens,
                            analysis_cost=self.total_cost
                        )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤
                    if tool_name == "get_metadata_structure" and tool_result and "–Ω–µ –Ω–∞–π–¥–µ–Ω–∞" not in tool_result:
                        collected_context.append(tool_result)
                        loaded_objects.append({
                            "type": tool_args.get("meta_type"),
                            "name": tool_args.get("name")
                        })
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º assistant message —Å tool_call
                    messages.append(ChatMessage(
                        role="assistant",
                        content="",
                        tool_calls=[tool_call]
                    ))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º tool response
                    messages.append(ChatMessage(
                        role="tool",
                        content=tool_result,
                        tool_call_id=tool_id
                    ))
            
            print("[–ê–≥–µ–Ω—Ç] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π")
            
            return ContextLoadResult(
                success=True,
                context_text="\n\n---\n\n".join(collected_context),
                objects_loaded=loaded_objects,
                analysis_tokens=self.total_tokens,
                analysis_cost=self.total_cost
            )
            
        except Exception as e:
            print(f"[–ê–≥–µ–Ω—Ç] –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return ContextLoadResult(
                success=False,
                error=str(e),
                analysis_tokens=self.total_tokens,
                analysis_cost=self.total_cost
            )


# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
SmartContextLoader = AgenticContextLoader
