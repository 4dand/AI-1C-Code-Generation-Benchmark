"""
Reporter ‚Äî –º–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

–§—É–Ω–∫—Ü–∏–∏:
- –ü–∞—Ä—Å–∏–Ω–≥ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–æ–≤
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict


@dataclass
class RunStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞"""
    run_index: int
    seed: int
    success: bool
    tokens_input: int = 0
    tokens_output: int = 0
    tokens_total: int = 0
    elapsed_time: float = 0.0
    cost_total: float = 0.0
    response_hash: str = ""
    error: Optional[str] = None


@dataclass
class TaskStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–¥–∞—á–µ"""
    task_id: str
    task_name: str
    model_id: str
    model_name: str
    category: str = ""
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–æ–Ω–æ–≤
    runs: List[RunStats] = field(default_factory=list)
    
    # –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º
    determinism_rate: float = 0.0
    unique_responses: int = 0
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç (–¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ B)
    context_loaded: bool = False
    context_objects: List[str] = field(default_factory=list)
    context_cost: float = 0.0
    
    # –ê–≥—Ä–µ–≥–∞—Ç—ã
    total_tokens: int = 0
    total_cost: float = 0.0
    avg_time: float = 0.0
    success_rate: float = 0.0


@dataclass
class ExperimentStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    experiment_file: str
    category: str
    timestamp: str
    
    # –ó–∞–¥–∞—á–∏
    tasks: List[TaskStats] = field(default_factory=list)
    
    # –ú–æ–¥–µ–ª–∏
    models_used: List[str] = field(default_factory=list)
    
    # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    total_tokens: int = 0
    total_cost: float = 0.0
    total_time: float = 0.0
    
    # –ê–≥—Ä–µ–≥–∞—Ç—ã
    avg_determinism: float = 0.0
    avg_success_rate: float = 0.0


class ResultsParser:
    """–ü–∞—Ä—Å–µ—Ä JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, results_dir: str = "results"):
        self.results_dir = Path(results_dir)
    
    def list_experiments(self, category: str = None) -> List[Path]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
        if not self.results_dir.exists():
            return []
        
        files = sorted(self.results_dir.glob("experiment_*.json"))
        
        if category:
            files = [f for f in files if f"_{category}_" in f.name]
        
        return files
    
    def parse_experiment(self, filepath: Path) -> Optional[ExperimentStats]:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            print(f"[Reporter] Error reading {filepath}: {e}")
            return None
        
        experiment = ExperimentStats(
            experiment_file=filepath.name,
            category=data.get("category", "?"),
            timestamp=data.get("timestamp", ""),
            models_used=data.get("models_used", []),
            total_tokens=data.get("total_tokens", 0),
            total_cost=data.get("total_cost", 0.0),
            total_time=data.get("total_time", 0.0)
        )
        
        # –ü–∞—Ä—Å–∏–º –∑–∞–¥–∞—á–∏
        for task_data in data.get("task_results", []):
            task = self._parse_task(task_data, experiment.category)
            experiment.tasks.append(task)
        
        # –°—á–∏—Ç–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ç—ã
        if experiment.tasks:
            experiment.avg_determinism = sum(t.determinism_rate for t in experiment.tasks) / len(experiment.tasks)
            experiment.avg_success_rate = sum(t.success_rate for t in experiment.tasks) / len(experiment.tasks)
        
        return experiment
    
    def _parse_task(self, data: Dict, category: str) -> TaskStats:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∑–∞–¥–∞—á—É"""
        task = TaskStats(
            task_id=data.get("task_id", ""),
            task_name=data.get("task_name", ""),
            model_id=data.get("model_id", ""),
            model_name=data.get("model_name", ""),
            category=category,
            total_tokens=data.get("total_tokens", 0),
            total_cost=data.get("total_cost", 0.0),
            avg_time=data.get("avg_time", 0.0)
        )
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç (–∫–∞—Ç–µ–≥–æ—Ä–∏—è B)
        task.context_loaded = data.get("context_loaded", False)
        task.context_cost = data.get("context_analysis_cost", 0.0)
        context_objs = data.get("context_objects", [])
        task.context_objects = [obj.get("name", "") for obj in context_objs if obj.get("name")]
        
        # –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º
        det = data.get("determinism", {})
        task.determinism_rate = det.get("match_rate", 0.0)
        task.unique_responses = det.get("unique_responses", 0)
        
        # –ü—Ä–æ–≥–æ–Ω—ã
        for run_data in data.get("runs", []):
            run = RunStats(
                run_index=run_data.get("run_index", 0),
                seed=run_data.get("seed", 0),
                success=run_data.get("success", False),
                tokens_input=run_data.get("tokens_input", 0),
                tokens_output=run_data.get("tokens_output", 0),
                tokens_total=run_data.get("tokens_total", 0),
                elapsed_time=run_data.get("elapsed_time", 0.0),
                cost_total=run_data.get("cost_total", 0.0),
                response_hash=run_data.get("response_hash", ""),
                error=run_data.get("error")
            )
            task.runs.append(run)
        
        # Success rate
        if task.runs:
            successful = sum(1 for r in task.runs if r.success)
            task.success_rate = successful / len(task.runs)
        
        return task


class ReportFormatter:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–æ–≤"""
    
    @staticmethod
    def format_cost(cost: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å"""
        if cost < 0.01:
            return f"${cost:.6f}"
        elif cost < 1:
            return f"${cost:.4f}"
        else:
            return f"${cost:.2f}"
    
    @staticmethod
    def format_tokens(tokens: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã"""
        if tokens >= 1_000_000:
            return f"{tokens/1_000_000:.2f}M"
        elif tokens >= 1_000:
            return f"{tokens/1_000:.1f}K"
        return str(tokens)
    
    @staticmethod
    def format_time(seconds: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è"""
        if seconds < 1:
            return f"{seconds*1000:.0f}ms"
        elif seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = seconds % 60
            return f"{minutes}m {secs:.0f}s"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours}h {minutes}m"
    
    @staticmethod
    def format_percent(value: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç"""
        return f"{value * 100:.1f}%"
    
    @staticmethod
    def determinism_emoji(rate: float) -> str:
        """–≠–º–æ–¥–∑–∏ –¥–ª—è —É—Ä–æ–≤–Ω—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞"""
        if rate >= 1.0:
            return "üü¢"  # 100%
        elif rate >= 0.8:
            return "üü°"  # 80%+
        elif rate >= 0.5:
            return "üü†"  # 50%+
        else:
            return "üî¥"  # <50%
    
    @staticmethod
    def success_emoji(rate: float) -> str:
        """–≠–º–æ–¥–∑–∏ –¥–ª—è success rate"""
        if rate >= 1.0:
            return "‚úÖ"
        elif rate >= 0.8:
            return "‚ö†Ô∏è"
        else:
            return "‚ùå"


class ExperimentReporter:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á—ë—Ç–æ–≤ –ø–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º"""
    
    def __init__(self, results_dir: str = "results"):
        self.parser = ResultsParser(results_dir)
        self.fmt = ReportFormatter()
    
    def print_experiment_summary(self, experiment: ExperimentStats):
        """–í—ã–≤–µ—Å—Ç–∏ –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""
        print()
        print("=" * 70)
        print(f"üìä –û–¢–ß–Å–¢: {experiment.experiment_file}")
        print("=" * 70)
        print()
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è:     {experiment.category}")
        print(f"  –î–∞—Ç–∞:          {experiment.timestamp[:19] if experiment.timestamp else 'N/A'}")
        print(f"  –ú–æ–¥–µ–ª–∏:        {', '.join(experiment.models_used)}")
        print(f"  –ó–∞–¥–∞—á:         {len(experiment.tasks)}")
        print()
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        print("‚îÄ" * 70)
        print("  üìà –û–ë–©–ò–ï –ú–ï–¢–†–ò–ö–ò")
        print("‚îÄ" * 70)
        print(f"  –¢–æ–∫–µ–Ω—ã:        {self.fmt.format_tokens(experiment.total_tokens)}")
        print(f"  –°—Ç–æ–∏–º–æ—Å—Ç—å:     {self.fmt.format_cost(experiment.total_cost)}")
        print(f"  –í—Ä–µ–º—è:         {self.fmt.format_time(experiment.total_time)}")
        print(f"  –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º:   {self.fmt.format_percent(experiment.avg_determinism)} {self.fmt.determinism_emoji(experiment.avg_determinism)}")
        print(f"  Success Rate:  {self.fmt.format_percent(experiment.avg_success_rate)} {self.fmt.success_emoji(experiment.avg_success_rate)}")
        print()
    
    def print_task_details(self, task: TaskStats):
        """–í—ã–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª–∏ –ø–æ –∑–∞–¥–∞—á–µ"""
        print("‚îÄ" * 70)
        print(f"  üìù {task.task_id}: {task.task_name}")
        print("‚îÄ" * 70)
        print(f"     –ú–æ–¥–µ–ª—å:        {task.model_name} ({task.model_id})")
        print(f"     –¢–æ–∫–µ–Ω—ã:        {self.fmt.format_tokens(task.total_tokens)}")
        print(f"     –°—Ç–æ–∏–º–æ—Å—Ç—å:     {self.fmt.format_cost(task.total_cost)}")
        print(f"     –°—Ä. –≤—Ä–µ–º—è:     {self.fmt.format_time(task.avg_time)}")
        print(f"     –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º:   {self.fmt.format_percent(task.determinism_rate)} ({task.unique_responses} —É–Ω–∏–∫.)")
        print(f"     Success Rate:  {self.fmt.format_percent(task.success_rate)} ({sum(1 for r in task.runs if r.success)}/{len(task.runs)})")
        
        if task.context_loaded:
            print(f"     –ö–æ–Ω—Ç–µ–∫—Å—Ç:      {', '.join(task.context_objects) or 'N/A'}")
            print(f"     –ö–æ–Ω—Ç–µ–∫—Å—Ç $:    {self.fmt.format_cost(task.context_cost)}")
        
        # –î–µ—Ç–∞–ª–∏ –ø—Ä–æ–≥–æ–Ω–æ–≤
        if task.runs:
            print()
            print(f"     –ü—Ä–æ–≥–æ–Ω—ã:")
            for run in task.runs:
                status = "‚úÖ" if run.success else "‚ùå"
                hash_short = run.response_hash[:8] if run.response_hash else "N/A"
                print(f"       {status} Run {run.run_index}: seed={run.seed}, "
                      f"tokens={run.tokens_total}, time={self.fmt.format_time(run.elapsed_time)}, "
                      f"hash={hash_short}")
                if run.error:
                    print(f"          ‚ö†Ô∏è  Error: {run.error[:60]}...")
        print()
    
    def print_full_report(self, filepath: Path):
        """–ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É"""
        experiment = self.parser.parse_experiment(filepath)
        if not experiment:
            print(f"[Reporter] Failed to parse {filepath}")
            return
        
        self.print_experiment_summary(experiment)
        
        for task in experiment.tasks:
            self.print_task_details(task)
    
    def print_comparison_table(self, experiments: List[ExperimentStats]):
        """–¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
        if not experiments:
            print("[Reporter] No experiments to compare")
            return
        
        print()
        print("=" * 90)
        print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í")
        print("=" * 90)
        print()
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        print(f"{'–§–∞–π–ª':<40} {'–ö–∞—Ç.':<4} {'–¢–æ–∫–µ–Ω—ã':<10} {'–°—Ç–æ–∏–º.':<12} {'–î–µ—Ç–µ—Ä–º.':<10} {'Success':<10}")
        print("-" * 90)
        
        for exp in experiments:
            print(f"{exp.experiment_file:<40} "
                  f"{exp.category:<4} "
                  f"{self.fmt.format_tokens(exp.total_tokens):<10} "
                  f"{self.fmt.format_cost(exp.total_cost):<12} "
                  f"{self.fmt.format_percent(exp.avg_determinism):<10} "
                  f"{self.fmt.format_percent(exp.avg_success_rate):<10}")
        
        print("-" * 90)
        
        # –ò—Ç–æ–≥–æ
        total_tokens = sum(e.total_tokens for e in experiments)
        total_cost = sum(e.total_cost for e in experiments)
        avg_det = sum(e.avg_determinism for e in experiments) / len(experiments)
        avg_success = sum(e.avg_success_rate for e in experiments) / len(experiments)
        
        print(f"{'–ò–¢–û–ì–û':<40} "
              f"{'':4} "
              f"{self.fmt.format_tokens(total_tokens):<10} "
              f"{self.fmt.format_cost(total_cost):<12} "
              f"{self.fmt.format_percent(avg_det):<10} "
              f"{self.fmt.format_percent(avg_success):<10}")
        print()
    
    def print_model_comparison(self, experiments: List[ExperimentStats]):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –º–æ–¥–µ–ª—è–º"""
        if not experiments:
            return
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–æ–¥–µ–ª—è–º
        model_stats: Dict[str, Dict] = defaultdict(lambda: {
            "tasks": 0,
            "tokens": 0,
            "cost": 0.0,
            "determinism_sum": 0.0,
            "success_sum": 0.0
        })
        
        for exp in experiments:
            for task in exp.tasks:
                stats = model_stats[task.model_name]
                stats["tasks"] += 1
                stats["tokens"] += task.total_tokens
                stats["cost"] += task.total_cost
                stats["determinism_sum"] += task.determinism_rate
                stats["success_sum"] += task.success_rate
        
        print()
        print("=" * 90)
        print("ü§ñ –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("=" * 90)
        print()
        
        print(f"{'–ú–æ–¥–µ–ª—å':<30} {'–ó–∞–¥–∞—á':<8} {'–¢–æ–∫–µ–Ω—ã':<12} {'–°—Ç–æ–∏–º.':<12} {'–î–µ—Ç–µ—Ä–º.':<10} {'Success':<10}")
        print("-" * 90)
        
        for model_name, stats in sorted(model_stats.items()):
            tasks = stats["tasks"]
            avg_det = stats["determinism_sum"] / tasks if tasks > 0 else 0
            avg_success = stats["success_sum"] / tasks if tasks > 0 else 0
            
            print(f"{model_name:<30} "
                  f"{tasks:<8} "
                  f"{self.fmt.format_tokens(stats['tokens']):<12} "
                  f"{self.fmt.format_cost(stats['cost']):<12} "
                  f"{self.fmt.format_percent(avg_det):<10} "
                  f"{self.fmt.format_percent(avg_success):<10}")
        
        print()
    
    def generate_report(self, category: str = None, latest: int = None):
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç
        
        Args:
            category: –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (A, B)
            latest: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        """
        files = self.parser.list_experiments(category)
        
        if latest:
            files = files[-latest:]
        
        if not files:
            print(f"[Reporter] No experiments found in {self.parser.results_dir}")
            return
        
        experiments = []
        for f in files:
            exp = self.parser.parse_experiment(f)
            if exp:
                experiments.append(exp)
        
        if len(experiments) == 1:
            # –û–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç
            self.print_full_report(files[0])
        else:
            # –ù–µ—Å–∫–æ–ª—å–∫–æ ‚Äî —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
            self.print_comparison_table(experiments)
            self.print_model_comparison(experiments)
    
    def export_markdown(self, experiment: ExperimentStats, output_path: str = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç –≤ Markdown
        
        Args:
            experiment: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            Markdown —Ç–µ–∫—Å—Ç
        """
        lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        lines.append(f"# üìä –û—Ç—á—ë—Ç: {experiment.experiment_file}")
        lines.append("")
        lines.append(f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {experiment.category}  ")
        lines.append(f"**–î–∞—Ç–∞:** {experiment.timestamp[:19] if experiment.timestamp else 'N/A'}  ")
        lines.append(f"**–ú–æ–¥–µ–ª–∏:** {', '.join(experiment.models_used)}  ")
        lines.append("")
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        lines.append("## üìà –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏")
        lines.append("")
        lines.append("| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |")
        lines.append("|---------|----------|")
        lines.append(f"| –¢–æ–∫–µ–Ω—ã | {self.fmt.format_tokens(experiment.total_tokens)} |")
        lines.append(f"| –°—Ç–æ–∏–º–æ—Å—Ç—å | {self.fmt.format_cost(experiment.total_cost)} |")
        lines.append(f"| –í—Ä–µ–º—è | {self.fmt.format_time(experiment.total_time)} |")
        lines.append(f"| –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º | {self.fmt.format_percent(experiment.avg_determinism)} {self.fmt.determinism_emoji(experiment.avg_determinism)} |")
        lines.append(f"| Success Rate | {self.fmt.format_percent(experiment.avg_success_rate)} {self.fmt.success_emoji(experiment.avg_success_rate)} |")
        lines.append("")
        
        # –ó–∞–¥–∞—á–∏
        lines.append("## üìù –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–¥–∞—á–∞–º")
        lines.append("")
        
        for task in experiment.tasks:
            lines.append(f"### {task.task_id}: {task.task_name}")
            lines.append("")
            lines.append(f"**–ú–æ–¥–µ–ª—å:** {task.model_name}  ")
            lines.append(f"**–¢–æ–∫–µ–Ω—ã:** {self.fmt.format_tokens(task.total_tokens)}  ")
            lines.append(f"**–°—Ç–æ–∏–º–æ—Å—Ç—å:** {self.fmt.format_cost(task.total_cost)}  ")
            lines.append(f"**–î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º:** {self.fmt.format_percent(task.determinism_rate)} ({task.unique_responses} —É–Ω–∏–∫.)  ")
            lines.append(f"**Success Rate:** {self.fmt.format_percent(task.success_rate)}  ")
            
            if task.context_loaded:
                lines.append(f"**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {', '.join(task.context_objects) or 'N/A'}  ")
            
            lines.append("")
            
            # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–≥–æ–Ω–æ–≤
            lines.append("| Run | Seed | Status | Tokens | Time | Hash |")
            lines.append("|-----|------|--------|--------|------|------|")
            
            for run in task.runs:
                status = "‚úÖ" if run.success else "‚ùå"
                hash_short = run.response_hash[:8] if run.response_hash else "-"
                lines.append(f"| {run.run_index} | {run.seed} | {status} | {run.tokens_total} | {self.fmt.format_time(run.elapsed_time)} | `{hash_short}` |")
            
            lines.append("")
        
        markdown = "\n".join(lines)
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown)
            print(f"[Reporter] Markdown saved to {output_path}")
        
        return markdown


# CLI interface
def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞")
    parser.add_argument("-c", "--category", choices=["A", "B"], help="–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    parser.add_argument("-n", "--latest", type=int, help="–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
    parser.add_argument("-f", "--file", help="–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--dir", default="results", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
    
    args = parser.parse_args()
    
    reporter = ExperimentReporter(args.dir)
    
    if args.file:
        reporter.print_full_report(Path(args.file))
    else:
        reporter.generate_report(category=args.category, latest=args.latest)


if __name__ == "__main__":
    main()
