"""
Dashboard ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ SMOP

–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
- FR-501: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ—Ü–µ–Ω–∫–∞–º–∏
- FR-502: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- FR-503: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á –∏ –ø—Ä–æ–≥–æ–Ω–æ–≤
- FR-504: –ü–∞–Ω–µ–ª—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∫–æ–¥–∞ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π
- FR-505: –ü–∞–Ω–µ–ª—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
- FR-506: –ü–∞–Ω–µ–ª—å –æ—Ü–µ–Ω–∫–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
- FR-507: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –æ—Ü–µ–Ω–∫–∏
- FR-508: –ù–∞–≤–∏–≥–∞—Ü–∏—è –º–µ–∂–¥—É –ø—Ä–æ–≥–æ–Ω–∞–º–∏
- FR-509: –ò–Ω–¥–∏–∫–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
- FR-510: –°–≤–æ–¥–Ω–∞—è –ø–∞–Ω–µ–ª—å –º–µ—Ç—Ä–∏–∫
- FR-511: CLI-—Ä–µ–∂–∏–º –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏

NFR-04: –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
NFR-05: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
"""

import logging
import time
from typing import Optional, List, Dict, Any, Tuple

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.layout import Layout
from rich.text import Text
from rich.prompt import Prompt, IntPrompt, Confirm
from rich.progress import Progress, BarColumn, TextColumn
from rich.syntax import Syntax
from rich.live import Live
from rich.markdown import Markdown

from ..schemas.results import ExperimentResult
from .schemas import ExperimentEvaluation, TaskEvaluation, RunEvaluation, SMOPScores, VALID_SCORES
from .parser import ExperimentParser
from .smop import SMOPEvaluator, SMOPCriteria, get_smop_criteria
from .statistics import StatisticsCalculator
from .report import ReportGenerator, generate_report


logger = logging.getLogger(__name__)
console = Console()


class EvaluatorDashboard:
    """
    –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π TUI-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ—à–∞–≥–æ–≤—É—é –Ω–∞–≤–∏–≥–∞—Ü–∏—é –ø–æ –ø—Ä–æ–≥–æ–Ω–∞–º —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é
    –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∫–æ–¥–∞, –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫ SMOP.
    
    Example:
        dashboard = EvaluatorDashboard()
        dashboard.run("experiment_B_20260205_221310")
    """
    
    def __init__(
        self,
        results_dir: str = "raw_results",
        evaluations_dir: str = "evaluations",
        reports_dir: str = "reports"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Dashboard
        
        Args:
            results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
            evaluations_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫
            reports_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
        """
        self.parser = ExperimentParser(results_dir)
        self.evaluator = SMOPEvaluator(evaluations_dir)
        self.criteria = get_smop_criteria()
        self.reports_dir = reports_dir
        
        # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.experiment: Optional[ExperimentResult] = None
        self.evaluation: Optional[ExperimentEvaluation] = None
        
        # –ù–∞–≤–∏–≥–∞—Ü–∏—è
        self.current_task_idx: int = 0
        self.current_run_idx: int = 0
        
        # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.last_save_time: float = 0
        self.autosave_interval: int = 30  # —Å–µ–∫—É–Ω–¥
    
    def list_experiments(self) -> None:
        """
        –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        
        FR-502: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        """
        experiments = self.parser.list_experiments()
        
        if not experiments:
            console.print("[yellow]–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ raw_results/[/yellow]")
            return
        
        table = Table(title="üìÇ –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã", show_header=True, header_style="bold cyan")
        table.add_column("ID", style="bright_white")
        table.add_column("–ö–∞—Ç–µ–≥–æ—Ä–∏—è", justify="center")
        table.add_column("–ú–æ–¥–µ–ª–∏", style="dim")
        table.add_column("–ó–∞–¥–∞—á", justify="right")
        table.add_column("–ü—Ä–æ–≥–æ–Ω–æ–≤", justify="right")
        table.add_column("–°—Ç–æ–∏–º–æ—Å—Ç—å", justify="right", style="green")
        
        for exp in experiments:
            models = ", ".join(exp.get("models", [])[:2])
            if len(exp.get("models", [])) > 2:
                models += "..."
            
            table.add_row(
                exp["id"],
                exp["category"],
                models,
                str(exp.get("tasks_count", 0)),
                str(exp.get("runs_per_task", 0)),
                f"${exp.get('total_cost', 0):.4f}"
            )
        
        console.print()
        console.print(table)
        console.print()
    
    def show_status(self, experiment_id: str) -> None:
        """
        –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –æ—Ü–µ–Ω–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        
        Args:
            experiment_id: ID —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        """
        evaluations = self.evaluator.list_evaluations(experiment_id)
        
        if not evaluations:
            console.print(f"[yellow]–û—Ü–µ–Ω–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ {experiment_id} –µ—â—ë –Ω–µ –Ω–∞—á–∞—Ç–∞[/yellow]")
            return
        
        table = Table(title=f"üìä –°—Ç–∞—Ç—É—Å –æ—Ü–µ–Ω–∫–∏: {experiment_id}", show_header=True)
        table.add_column("–≠–∫—Å–ø–µ—Ä—Ç", style="cyan")
        table.add_column("–°—Ç–∞—Ç—É—Å", justify="center")
        table.add_column("–ü—Ä–æ–≥—Ä–µ—Å—Å", justify="center")
        table.add_column("–û—Ü–µ–Ω–µ–Ω–æ", justify="right")
        table.add_column("–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ", style="dim")
        
        for ev in evaluations:
            status_style = {
                "not_started": "dim",
                "in_progress": "yellow",
                "completed": "green"
            }.get(ev["status"], "white")
            
            progress_bar = self._make_progress_bar(ev["progress_percent"])
            
            table.add_row(
                ev["evaluator_id"],
                f"[{status_style}]{ev['status']}[/{status_style}]",
                progress_bar,
                f"{ev['evaluated_runs']}/{ev['total_runs']}",
                ev.get("last_modified_at", "-")[:16] if ev.get("last_modified_at") else "-"
            )
        
        console.print()
        console.print(table)
        console.print()
    
    def _make_progress_bar(self, percent: float) -> str:
        """–°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é –ø–æ–ª–æ—Å–∫—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        filled = int(percent / 5)  # 20 —Å–∏–º–≤–æ–ª–æ–≤ = 100%
        empty = 20 - filled
        bar = "‚ñà" * filled + "‚ñë" * empty
        color = "green" if percent >= 80 else ("yellow" if percent >= 40 else "red")
        return f"[{color}]{bar}[/{color}] {percent:.0f}%"
    
    def run(self, experiment_id: str, evaluator_id: str = "expert_01") -> None:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –æ—Ü–µ–Ω–∫–∏
        
        Args:
            experiment_id: ID —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            evaluator_id: ID —ç–∫—Å–ø–µ—Ä—Ç–∞
            
        FR-501: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
        self.experiment = self.parser.load_experiment(experiment_id)
        if not self.experiment:
            console.print(f"[red]–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {experiment_id}[/red]")
            return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –æ—Ü–µ–Ω–∫—É
        self.evaluation = self.evaluator.load(experiment_id, evaluator_id)
        
        if self.evaluation:
            console.print(f"[green]–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å–µ—Å—Å–∏—è –æ—Ü–µ–Ω–∫–∏ ({self.evaluation.progress_percent:.0f}%)[/green]")
        else:
            self.evaluation = self.parser.create_evaluation(self.experiment, evaluator_id)
            self.evaluation.start()
            console.print("[cyan]–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å–µ—Å—Å–∏—è –æ—Ü–µ–Ω–∫–∏[/cyan]")
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤—ã–π –Ω–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã–π –ø—Ä–æ–≥–æ–Ω
        self._find_first_unevaluated()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        self._main_loop()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ
        self._save()
        console.print("[green]‚úì –û—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã[/green]")
    
    def _find_first_unevaluated(self) -> None:
        """–ù–∞–π—Ç–∏ –ø–µ—Ä–≤—ã–π –Ω–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã–π –ø—Ä–æ–≥–æ–Ω"""
        for task_idx, task in enumerate(self.evaluation.tasks):
            for run_idx, run in enumerate(task.runs):
                if not run.scores.is_complete:
                    self.current_task_idx = task_idx
                    self.current_run_idx = run_idx
                    return
    
    def _main_loop(self) -> None:
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        while True:
            self._autosave_check()
            
            # –û—á–∏—â–∞–µ–º —ç–∫—Ä–∞–Ω
            console.clear()
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
            self._render_header()
            self._render_current_run()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã
            action = self._prompt_action()
            
            if action == "quit":
                break
            elif action == "next":
                self._navigate_next()
            elif action == "prev":
                self._navigate_prev()
            elif action == "save":
                self._save()
            elif action == "report":
                self._generate_report()
            elif action == "score":
                self._input_scores()
            elif action == "jump":
                self._jump_to_run()
    
    def _render_header(self) -> None:
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
        task = self._get_current_task()
        run = self._get_current_run()
        
        if not task or not run:
            return
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å
        progress_text = self._make_progress_bar(self.evaluation.progress_percent)
        
        header = Table.grid(expand=True)
        header.add_column(ratio=3)
        header.add_column(ratio=2, justify="right")
        
        header.add_row(
            f"[bold cyan]SMOP Evaluator[/bold cyan] ‚îÇ {self.experiment.experiment_name}",
            f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_text}"
        )
        
        console.print(Panel(header, style="blue"))
        console.print()
    
    def _render_current_run(self) -> None:
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞"""
        task = self._get_current_task()
        run = self._get_current_run()
        
        if not task or not run:
            console.print("[red]–ù–µ—Ç –ø—Ä–æ–≥–æ–Ω–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏[/red]")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        details = self.parser.get_run_details(
            self.experiment,
            task.task_id,
            task.model_id,
            run.run_index
        )
        
        if not details:
            console.print("[red]–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–≥–æ–Ω–∞[/red]")
            return
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∑–∞–¥–∞—á–∏
        console.print(Panel(
            f"[bold]–ó–∞–¥–∞—á–∞:[/bold] {task.task_id} ‚îÇ "
            f"[bold]–ú–æ–¥–µ–ª—å:[/bold] {task.model_name} ‚îÇ "
            f"[bold]–ü—Ä–æ–≥–æ–Ω:[/bold] {run.run_index + 1}/{len(task.runs)}",
            style="cyan"
        ))
        
        # Layout –¥–ª—è –¥–≤—É—Ö –ø–∞–Ω–µ–ª–µ–π
        layout = Layout()
        layout.split_row(
            Layout(name="left", ratio=1),
            Layout(name="right", ratio=1)
        )
        
        # –õ–µ–≤–∞—è –ø–∞–Ω–µ–ª—å: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∫–æ–¥
        code = details.get("code", "")[:2000]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è TUI
        
        code_panel = Panel(
            Syntax(code, "vbnet", theme="monokai", line_numbers=True, word_wrap=True),
            title="üìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥",
            border_style="green"
        )
        console.print(code_panel)
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if details.get("context_objects"):
            ctx_lines = []
            for obj in details["context_objects"][:5]:
                ctx_lines.append(f"‚Ä¢ {obj.get('type', '?')}: {obj.get('name', '?')}")
            ctx_text = "\n".join(ctx_lines) if ctx_lines else "–ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
            console.print(Panel(ctx_text, title="üì¶ –ö–æ–Ω—Ç–µ–∫—Å—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö", border_style="blue"))
        
        # –ü–∞–Ω–µ–ª—å —Ç–µ–∫—É—â–∏—Ö –æ—Ü–µ–Ω–æ–∫
        self._render_scores_panel(run)
    
    def _render_scores_panel(self, run: RunEvaluation) -> None:
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –ø–∞–Ω–µ–ª–∏ —Ç–µ–∫—É—â–∏—Ö –æ—Ü–µ–Ω–æ–∫"""
        scores = run.scores
        
        table = Table(show_header=True, header_style="bold", expand=True)
        table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan", width=20)
        table.add_column("–û—Ü–µ–Ω–∫–∞", justify="center", width=10)
        table.add_column("–ö—Ä–∏—Ç–µ—Ä–∏–π", style="dim")
        
        for metric in ["S", "M", "O", "P"]:
            score = getattr(scores, metric)
            score_str = str(score) if score is not None else "[dim]‚Äî[/dim]"
            
            criterion = ""
            if score is not None:
                criterion = self.criteria.get_criterion_description(metric, score)[:60]
                if len(self.criteria.get_criterion_description(metric, score)) > 60:
                    criterion += "..."
            
            info = self.criteria.get_metric_info(metric)
            metric_name = f"{metric} ({info.get('name', '')})"
            
            table.add_row(metric_name, score_str, criterion)
        
        # Q
        q_val = f"[bold]{scores.Q:.1f}[/bold]" if scores.Q is not None else "[dim]‚Äî[/dim]"
        quality = ""
        if scores.quality_level:
            level_colors = {"high": "green", "acceptable": "yellow", "low": "red"}
            level_names = {"high": "–í—ã—Å–æ–∫–∏–π", "acceptable": "–ü—Ä–∏–µ–º–ª–µ–º—ã–π", "low": "–ù–∏–∑–∫–∏–π"}
            color = level_colors.get(scores.quality_level, "white")
            quality = f"[{color}]{level_names.get(scores.quality_level, '')}[/{color}]"
        
        table.add_row("[bold]Q (–ò—Ç–æ–≥–æ)[/bold]", q_val, quality)
        
        console.print(Panel(table, title="üìä –û—Ü–µ–Ω–∫–∏ SMOP", border_style="yellow"))
        
        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        if run.comment:
            console.print(Panel(run.comment, title="üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", border_style="dim"))
    
    def _prompt_action(self) -> str:
        """–ó–∞–ø—Ä–æ—Å –¥–µ–π—Å—Ç–≤–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        console.print()
        console.print("[dim]–ö–æ–º–∞–Ω–¥—ã: [S]core  [N]ext  [P]rev  [J]ump  [R]eport  [Q]uit[/dim]")
        
        action = Prompt.ask(
            "–î–µ–π—Å—Ç–≤–∏–µ",
            choices=["s", "n", "p", "j", "r", "q", "save"],
            default="s"
        ).lower()
        
        mapping = {
            "s": "score",
            "n": "next",
            "p": "prev",
            "j": "jump",
            "r": "report",
            "q": "quit",
            "save": "save"
        }
        
        return mapping.get(action, "score")
    
    def _input_scores(self) -> None:
        """–í–≤–æ–¥ –æ—Ü–µ–Ω–æ–∫ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞"""
        task = self._get_current_task()
        run = self._get_current_run()
        
        if not task or not run:
            return
        
        console.print()
        console.print("[bold cyan]–í–≤–µ–¥–∏—Ç–µ –æ—Ü–µ–Ω–∫–∏ (0, 2, 4, 6, 8, 10):[/bold cyan]")
        console.print("[dim]–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞[/dim]")
        console.print()
        
        scores = {}
        
        for metric in ["S", "M", "O", "P"]:
            info = self.criteria.get_metric_info(metric)
            current = getattr(run.scores, metric)
            default = str(current) if current is not None else ""
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏
            console.print(f"[bold]{metric}[/bold]: {info.get('name', '')}")
            console.print(f"[dim]{info.get('description', '')}[/dim]")
            
            while True:
                try:
                    value = Prompt.ask(f"  –û—Ü–µ–Ω–∫–∞ {metric}", default=default)
                    
                    if not value:
                        break
                    
                    score = int(value)
                    if score not in VALID_SCORES:
                        console.print(f"[red]–î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {sorted(VALID_SCORES)}[/red]")
                        continue
                    
                    scores[metric] = score
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π
                    criterion = self.criteria.get_criterion_description(metric, score)
                    if criterion:
                        console.print(f"  [dim]‚Üí {criterion}[/dim]")
                    break
                    
                except ValueError:
                    console.print("[red]–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ[/red]")
        
        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        comment = Prompt.ask("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", default=run.comment)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ü–µ–Ω–∫–∏
        if scores:
            self.evaluator.set_all_scores(
                self.evaluation,
                task.task_id,
                task.model_id,
                run.run_index,
                scores,
                comment
            )
            console.print("[green]‚úì –û—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã[/green]")
        
        # –ê–≤—Ç–æ–ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É
        if run.scores.is_complete:
            if Confirm.ask("–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–≥–æ–Ω—É?", default=True):
                self._navigate_next()
    
    def _navigate_next(self) -> None:
        """–ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–≥–æ–Ω—É"""
        task = self._get_current_task()
        
        if self.current_run_idx < len(task.runs) - 1:
            self.current_run_idx += 1
        elif self.current_task_idx < len(self.evaluation.tasks) - 1:
            self.current_task_idx += 1
            self.current_run_idx = 0
        else:
            console.print("[yellow]–î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞[/yellow]")
    
    def _navigate_prev(self) -> None:
        """–ü–µ—Ä–µ—Ö–æ–¥ –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –ø—Ä–æ–≥–æ–Ω—É"""
        if self.current_run_idx > 0:
            self.current_run_idx -= 1
        elif self.current_task_idx > 0:
            self.current_task_idx -= 1
            task = self._get_current_task()
            self.current_run_idx = len(task.runs) - 1
        else:
            console.print("[yellow]–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞[/yellow]")
    
    def _jump_to_run(self) -> None:
        """–ü–µ—Ä–µ—Ö–æ–¥ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø—Ä–æ–≥–æ–Ω—É"""
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
        table = Table(title="–ó–∞–¥–∞—á–∏", show_header=True)
        table.add_column("#", justify="right")
        table.add_column("ID")
        table.add_column("–ú–æ–¥–µ–ª—å")
        table.add_column("–ü—Ä–æ–≥–æ–Ω–æ–≤")
        table.add_column("–û—Ü–µ–Ω–µ–Ω–æ")
        
        for idx, task in enumerate(self.evaluation.tasks):
            table.add_row(
                str(idx + 1),
                task.task_id,
                task.model_name,
                str(task.total_runs),
                f"{task.evaluated_runs}/{task.total_runs}"
            )
        
        console.print(table)
        
        try:
            task_num = IntPrompt.ask("–ù–æ–º–µ—Ä –∑–∞–¥–∞—á–∏", default=self.current_task_idx + 1)
            if 1 <= task_num <= len(self.evaluation.tasks):
                self.current_task_idx = task_num - 1
                self.current_run_idx = 0
            
            task = self._get_current_task()
            run_num = IntPrompt.ask("–ù–æ–º–µ—Ä –ø—Ä–æ–≥–æ–Ω–∞", default=1)
            if 1 <= run_num <= len(task.runs):
                self.current_run_idx = run_num - 1
                
        except ValueError:
            pass
    
    def _save(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫–∏"""
        if self.evaluation:
            self.evaluator.save(self.evaluation)
            self.last_save_time = time.time()
    
    def _autosave_check(self) -> None:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        if time.time() - self.last_save_time > self.autosave_interval:
            self._save()
    
    def _generate_report(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞"""
        if not self.evaluation.is_complete:
            if not Confirm.ask("[yellow]–û—Ü–µ–Ω–∫–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã–π –æ—Ç—á—ë—Ç?[/yellow]"):
                return
        
        paths = generate_report(
            self.evaluation,
            self.experiment,
            self.reports_dir,
            formats=["json", "html"]
        )
        
        console.print("[green]‚úì –û—Ç—á—ë—Ç—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã:[/green]")
        for fmt, path in paths.items():
            console.print(f"  {fmt}: {path}")
    
    def _get_current_task(self) -> Optional[TaskEvaluation]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∑–∞–¥–∞—á—É"""
        if 0 <= self.current_task_idx < len(self.evaluation.tasks):
            return self.evaluation.tasks[self.current_task_idx]
        return None
    
    def _get_current_run(self) -> Optional[RunEvaluation]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥–æ–Ω"""
        task = self._get_current_task()
        if task and 0 <= self.current_run_idx < len(task.runs):
            return task.runs[self.current_run_idx]
        return None


def run_dashboard(
    experiment_id: str,
    evaluator_id: str = "expert_01",
    results_dir: str = "raw_results",
    evaluations_dir: str = "evaluations",
    reports_dir: str = "reports"
) -> None:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –æ—Ü–µ–Ω–∫–∏
    
    Args:
        experiment_id: ID —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        evaluator_id: ID —ç–∫—Å–ø–µ—Ä—Ç–∞
        results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        evaluations_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ü–µ–Ω–æ–∫
        reports_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
    """
    dashboard = EvaluatorDashboard(results_dir, evaluations_dir, reports_dir)
    dashboard.run(experiment_id, evaluator_id)


def list_experiments_cli(results_dir: str = "raw_results") -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ CLI"""
    dashboard = EvaluatorDashboard(results_dir)
    dashboard.list_experiments()


def show_status_cli(experiment_id: str, evaluations_dir: str = "evaluations") -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –æ—Ü–µ–Ω–∫–∏ –≤ CLI"""
    dashboard = EvaluatorDashboard(evaluations_dir=evaluations_dir)
    dashboard.show_status(experiment_id)
