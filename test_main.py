"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞ –ò–ò-–º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ MCP tool calling.
–¶–µ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏: Claude Opus 4.5, GPT-5.2-Codex, Gemini 3 Pro
"""

import os
import json
import requests
import hashlib
import time
from datetime import datetime

# ============== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==============
API_KEY = os.getenv("OPENROUTER_API_KEY", "sk-your-api-key-here")
BASE_URL = "https://openrouter.ai/api/v1"

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
    "HTTP-Referer": "https://1c-benchmark.local",
    "X-Title": "1C Benchmark Determinism Test"
}

# –¶–µ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ ID –∏–∑ OpenRouter)
MODELS = {
    "opus": {
        "id": "anthropic/claude-opus-4.5",
        "name": "Claude Opus 4.5",
        "api_type": "chat",  # OpenRouter —É–Ω–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç API
        "determinism_param": "temperature",  # –î–ª—è Anthropic –∏—Å–ø–æ–ª—å–∑—É–µ–º temperature=0
    },
    "gpt": {
        "id": "openai/gpt-5.2-codex",
        "name": "GPT-5.2-Codex",
        "api_type": "chat",
        "determinism_param": "seed",
    },
    "gemini": {
        "id": "google/gemini-3-flash-preview",
        "name": "Gemini 3 Flash",
        "api_type": "chat",
        "determinism_param": "seed",
    }
}

# –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ 1–° (–º–∏–Ω–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤)
TASKS_1C = [
    {
        "id": 1,
        "name": "–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–ª–æ–∂–µ–Ω–∏—è",
        "prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ 1–°:–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8 –∫–æ—Ç–æ—Ä–∞—è —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç –¥–≤–∞ —á–∏—Å–ª–∞. –¢–æ–ª—å–∫–æ –∫–æ–¥, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
    },
    {
        "id": 2,
        "name": "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É",
        "prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ 1–°:–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8 –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—É—Å—Ç–∞—è –ª–∏ —Å—Ç—Ä–æ–∫–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ò—Å—Ç–∏–Ω–∞/–õ–æ–∂—å. –¢–æ–ª—å–∫–æ –∫–æ–¥."
    }
]

# MCP Tool –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Ä—É—Å—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å system prompt!)
MCP_TOOL = {
    "type": "function",
    "function": {
        "name": "execute_1c_code",
        "description": "–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–¥ 1–°:–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
        "parameters": {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string",
                    "description": "–ö–æ–¥ –Ω–∞ —è–∑—ã–∫–µ 1–° –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
                },
                "params": {
                    "type": "object",
                    "description": "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –∫–æ–¥"
                }
            },
            "required": ["code"]
        }
    }
}


def log(message, level="INFO"):
    """–ü—Ä–æ—Å—Ç–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")


def get_balance():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å"""
    try:
        response = requests.get(f"{BASE_URL}/auth/key", headers=HEADERS)
        if response.status_code == 200:
            data = response.json().get('data', {})
            limit = data.get('limit', 0)
            usage = data.get('usage', 0)
            return {
                "limit": limit,
                "usage": usage,
                "available": limit - usage if limit else "unlimited"
            }
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞: {e}", "ERROR")
    return None


def get_model_info(model_id):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
    try:
        response = requests.get(f"{BASE_URL}/models", headers=HEADERS)
        if response.status_code == 200:
            models = response.json().get('data', [])
            for model in models:
                if model.get('id') == model_id:
                    return {
                        "full_id": model.get('id'),
                        "name": model.get('name'),
                        "context_length": model.get('context_length'),
                        "supported_parameters": model.get('supported_parameters', []),
                        "pricing": model.get('pricing', {}),
                        "architecture": model.get('architecture', {})
                    }
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è info –æ –º–æ–¥–µ–ª–∏: {e}", "ERROR")
    return None


def compute_hash(text):
    """–í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö–µ—à —Ç–µ–∫—Å—Ç–∞"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()


def call_model(model_key, prompt, seed=None, temperature=None, tools=None):
    """
    –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ OpenRouter
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (response_text, usage_info, elapsed_time, raw_response)
    """
    model = MODELS[model_key]
    
    request_body = {
        "model": model["id"],
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 500
    }
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
    if model["determinism_param"] == "seed" and seed is not None:
        request_body["seed"] = seed
        request_body["temperature"] = 0  # –î–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞ –Ω—É–∂–µ–Ω –∏ temperature=0
    elif model["determinism_param"] == "temperature":
        # –î–ª—è Claude: temperature=0 –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
        request_body["temperature"] = temperature if temperature is not None else 0
    
    # –î–æ–±–∞–≤–ª—è–µ–º tools –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if tools:
        request_body["tools"] = tools
        request_body["tool_choice"] = "auto"
    
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{BASE_URL}/chat/completions",
            headers=HEADERS,
            json=request_body,
            timeout=60
        )
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            data = response.json()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            choices = data.get('choices', [])
            if choices:
                message = choices[0].get('message', {})
                content = message.get('content', '')
                tool_calls = message.get('tool_calls', [])
            else:
                content = ""
                tool_calls = []
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
            usage = data.get('usage', {})
            
            return {
                "success": True,
                "content": content,
                "tool_calls": tool_calls,
                "usage": usage,
                "elapsed": elapsed,
                "model_used": data.get('model', model["id"]),
                "raw": data
            }
        else:
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text[:200]}",
                "elapsed": elapsed
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "elapsed": time.time() - start_time
        }


def test_determinism(model_key, task, seed1=42, seed2=42, seed3=999):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º –º–æ–¥–µ–ª–∏:
    - 2 –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º seed -> –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã
    - 1 –∑–∞–ø—Ä–æ—Å —Å –¥—Ä—É–≥–∏–º seed -> –¥–æ–ª–∂–µ–Ω –æ—Ç–ª–∏—á–∞—Ç—å—Å—è
    """
    model = MODELS[model_key]
    log(f"üß™ –¢–µ—Å—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞: {model['name']} | –ó–∞–¥–∞—á–∞: {task['name']}")
    
    results = []
    
    # –î–ª—è Claude –∏—Å–ø–æ–ª—å–∑—É–µ–º temperature –≤–º–µ—Å—Ç–æ seed
    if model["determinism_param"] == "temperature":
        # –ó–∞–ø—Ä–æ—Å 1 –∏ 2 —Å temperature=0
        log(f"   –ó–∞–ø—Ä–æ—Å 1 (temperature=0)...")
        r1 = call_model(model_key, task["prompt"], temperature=0)
        results.append(r1)
        
        log(f"   –ó–∞–ø—Ä–æ—Å 2 (temperature=0)...")
        r2 = call_model(model_key, task["prompt"], temperature=0)
        results.append(r2)
        
        # –ó–∞–ø—Ä–æ—Å 3 —Å temperature=0.7 (–¥–æ–ª–∂–µ–Ω –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
        log(f"   –ó–∞–ø—Ä–æ—Å 3 (temperature=0.7)...")
        r3 = call_model(model_key, task["prompt"], temperature=0.7)
        results.append(r3)
    else:
        # –î–ª—è GPT –∏ Gemini –∏—Å–ø–æ–ª—å–∑—É–µ–º seed
        log(f"   –ó–∞–ø—Ä–æ—Å 1 (seed={seed1})...")
        r1 = call_model(model_key, task["prompt"], seed=seed1)
        results.append(r1)
        
        log(f"   –ó–∞–ø—Ä–æ—Å 2 (seed={seed2})...")
        r2 = call_model(model_key, task["prompt"], seed=seed2)
        results.append(r2)
        
        log(f"   –ó–∞–ø—Ä–æ—Å 3 (seed={seed3})...")
        r3 = call_model(model_key, task["prompt"], seed=seed3)
        results.append(r3)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n   üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    
    hashes = []
    for i, r in enumerate(results, 1):
        if r["success"]:
            h = compute_hash(r["content"])
            hashes.append(h)
            print(f"   –û—Ç–≤–µ—Ç {i}: {h[:16]}... | –¢–æ–∫–µ–Ω—ã: {r['usage'].get('total_tokens', 'N/A')} | –í—Ä–µ–º—è: {r['elapsed']:.2f}—Å")
            print(f"            –ú–æ–¥–µ–ª—å: {r['model_used']}")
        else:
            hashes.append(None)
            print(f"   –û—Ç–≤–µ—Ç {i}: –û–®–ò–ë–ö–ê - {r['error'][:50]}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
    print("\n   üîç –ü–†–û–í–ï–†–ö–ê –î–ï–¢–ï–†–ú–ò–ù–ò–ó–ú–ê:")
    if hashes[0] and hashes[1]:
        if hashes[0] == hashes[1]:
            print(f"   ‚úÖ –û—Ç–≤–µ—Ç—ã 1 –∏ 2 –ò–î–ï–ù–¢–ò–ß–ù–´ (—Ö–µ—à–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç)")
        else:
            print(f"   ‚ùå –û—Ç–≤–µ—Ç—ã 1 –∏ 2 –†–ê–ó–õ–ò–ß–ê–Æ–¢–°–Ø (—Ö–µ—à–∏ –ù–ï —Å–æ–≤–ø–∞–¥–∞—é—Ç)")
            print(f"      Hash1: {hashes[0]}")
            print(f"      Hash2: {hashes[1]}")
    
    if hashes[0] and hashes[2]:
        if hashes[0] != hashes[2]:
            print(f"   ‚úÖ –û—Ç–≤–µ—Ç 3 –û–¢–õ–ò–ß–ê–ï–¢–°–Ø –æ—Ç 1 –∏ 2 (–∫–∞–∫ –∏ –æ–∂–∏–¥–∞–ª–æ—Å—å)")
        else:
            print(f"   ‚ö†Ô∏è  –û—Ç–≤–µ—Ç 3 –°–û–í–ü–ê–õ —Å 1 (–≤–æ–∑–º–æ–∂–Ω–æ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å)")
    
    return results


def test_mcp_tools(model_key):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É MCP tool calling"""
    model = MODELS[model_key]
    log(f"üîß –¢–µ—Å—Ç MCP Tools: {model['name']}")
    
    # System prompt –Ω—É–∂–µ–Ω –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ tools (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è Gemini)
    messages = [
        {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞ 1–°. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç execute_1c_code –∫–æ–≥–¥–∞ –ø—Ä–æ—Å—è—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥."},
        {"role": "user", "content": "–í—ã–ø–æ–ª–Ω–∏ –∫–æ–¥ 1–°: –°–ª–æ–∂–∏—Ç—å–ß–∏—Å–ª–∞(5, 3)"}
    ]
    
    request_body = {
        "model": model["id"],
        "messages": messages,
        "tools": [MCP_TOOL],
        "tool_choice": "auto",
        "max_tokens": 200,
        "temperature": 0
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{BASE_URL}/chat/completions",
            headers=HEADERS,
            json=request_body,
            timeout=60
        )
        elapsed = time.time() - start_time
        
        result = {"success": False, "elapsed": elapsed}
        
        if response.status_code == 200:
            data = response.json()
            choices = data.get('choices', [])
            if choices:
                message = choices[0].get('message', {})
                result = {
                    "success": True,
                    "content": message.get('content', ''),
                    "tool_calls": message.get('tool_calls', []),
                    "usage": data.get('usage', {}),
                    "elapsed": elapsed,
                    "model_used": data.get('model', model["id"])
                }
        else:
            result["error"] = f"HTTP {response.status_code}: {response.text[:100]}"
            
    except Exception as e:
        result = {"success": False, "error": str(e), "elapsed": time.time() - start_time}
    
    print(f"\n   üìä –†–ï–ó–£–õ–¨–¢–ê–¢ MCP –¢–ï–°–¢–ê:")
    if result["success"]:
        print(f"   –í—Ä–µ–º—è: {result['elapsed']:.2f}—Å | –¢–æ–∫–µ–Ω—ã: {result['usage'].get('total_tokens', 'N/A')}")
        
        if result["tool_calls"]:
            print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –≤—ã–∑–≤–∞–ª–∞ tool!")
            for tc in result["tool_calls"]:
                func = tc.get('function', {})
                print(f"      Tool: {func.get('name')}")
                print(f"      Args: {func.get('arguments')}")
        else:
            print(f"   ‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –ù–ï –≤—ã–∑–≤–∞–ª–∞ tool")
            print(f"      –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç: {result['content'][:200]}...")
    else:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê: {result.get('error', 'Unknown')}")
    
    return result


def main():
    print("=" * 80)
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –î–ï–¢–ï–†–ú–ò–ù–ò–ó–ú–ê –ò MCP –î–õ–Ø –ò–ò-–ú–û–î–ï–õ–ï–ô")
    print("   –¶–µ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏: Claude Opus 4.5, GPT-5.2-Codex, Gemini 3 Flash")
    print("=" * 80)
    
    # 1. –ù–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
    print("\nüìä –ù–ê–ß–ê–õ–¨–ù–´–ô –ë–ê–õ–ê–ù–°:")
    balance_start = get_balance()
    if balance_start:
        print(f"   –õ–∏–º–∏—Ç: ${balance_start['limit']}")
        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ${balance_start['usage']}")
        print(f"   –î–æ—Å—Ç—É–ø–Ω–æ: ${balance_start['available']}")
    
    # 2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
    print("\n" + "=" * 80)
    print("üìã –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–Ø–•:")
    print("=" * 80)
    
    for key, model in MODELS.items():
        info = get_model_info(model["id"])
        if info:
            print(f"\nü§ñ {model['name']}:")
            print(f"   ID: {info['full_id']}")
            print(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {info['context_length']:,} —Ç–æ–∫–µ–Ω–æ–≤")
            print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {', '.join(info['supported_parameters'][:10])}...")
            pricing = info['pricing']
            if pricing:
                inp = float(pricing.get('prompt', 0)) * 1_000_000
                out = float(pricing.get('completion', 0)) * 1_000_000
                print(f"   –¶–µ–Ω–∞: ${inp:.2f}/${out:.2f} –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤")
        else:
            print(f"\n‚ö†Ô∏è  {model['name']}: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
    
    # 3. –¢–µ—Å—Ç—ã –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
    print("\n" + "=" * 80)
    print("üß™ –¢–ï–°–¢–´ –î–ï–¢–ï–†–ú–ò–ù–ò–ó–ú–ê:")
    print("=" * 80)
    
    all_results = {}
    
    for model_key in MODELS:
        print(f"\n{'‚îÄ' * 60}")
        for task in TASKS_1C:
            results = test_determinism(model_key, task)
            all_results[f"{model_key}_{task['id']}"] = results
            print()
    
    # 4. –¢–µ—Å—Ç—ã MCP
    print("\n" + "=" * 80)
    print("üîß –¢–ï–°–¢–´ MCP TOOL CALLING:")
    print("=" * 80)
    
    mcp_results = {}
    for model_key in MODELS:
        print(f"\n{'‚îÄ' * 60}")
        mcp_results[model_key] = test_mcp_tools(model_key)
    
    # 5. –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–∞–Ω—Å
    print("\n" + "=" * 80)
    print("üìä –ò–¢–û–ì–û–í–´–ô –ë–ê–õ–ê–ù–°:")
    balance_end = get_balance()
    if balance_end and balance_start:
        spent = balance_end['usage'] - balance_start['usage']
        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ${balance_end['usage']}")
        print(f"   –î–æ—Å—Ç—É–ø–Ω–æ: ${balance_end['available']}")
        print(f"   üí∞ –ü–æ—Ç—Ä–∞—á–µ–Ω–æ –∑–∞ —Å–µ—Å—Å–∏—é: ${spent}")
    
    # 6. –°–≤–æ–¥–∫–∞
    print("\n" + "=" * 80)
    print("üìù –°–í–û–î–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print("=" * 80)
    
    print("\nüîπ –î–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º:")
    for model_key, model in MODELS.items():
        param = model["determinism_param"]
        print(f"   {model['name']}: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç {param}")
    
    print("\nüîπ MCP Tool Calling:")
    for model_key, result in mcp_results.items():
        model = MODELS[model_key]
        if result["success"]:
            has_tools = "‚úÖ –î–ê" if result.get("tool_calls") else "‚ö†Ô∏è –ù–ï–¢"
            print(f"   {model['name']}: {has_tools}")
        else:
            print(f"   {model['name']}: ‚ùå –û–®–ò–ë–ö–ê")
    
    print("\n" + "=" * 80)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)


if __name__ == "__main__":
    main()
